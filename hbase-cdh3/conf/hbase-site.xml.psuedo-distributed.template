<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Copyright 2009 The Apache Software Foundation
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<configuration>

<!-- NEEDED WHETHER OR NOT YOU ARE RUNNING OVER HDFS -->
<property>
  <name>hbase.cluster.distributed</name>
  <value>true</value>
  <description>For psuedo-distributed, you want to set this to true.
  false means that HBase tries to put Master + RegionServers in one process.
  Pseudo-distributed = seperate processes/pids</description>
</property> <property>
  <name>hbase.regionserver.hlog.replication</name>
  <value>1</value>
  <description>For HBase to offer good data durability, we roll logs if
  filesystem replication falls below a certain amount.  In psuedo-distributed
  mode, you normally only have the local filesystem or 1 HDFS DataNode, so you
  don't want to roll logs constantly.</description>
</property>
<property>
  <name>hbase.tmp.dir</name>
  <value>/tmp/hbase-testing</value>
  <description>Temporary directory on the local filesystem.</description>
</property>

<!-- DEFAULT = use local filesystem, not HDFS
     ADD THESE LINES if you have a copy of HDFS source and want to run HBase
     psuedo-distributed over a psuedo-distributed HDFS cluster.
     For HDFS psuedo-distributed setup, see their documentation:

     http://hadoop.apache.org/common/docs/r0.20.2/quickstart.html#PseudoDistributed


<property>
  <name>hbase.rootdir</name>
  <value>hdfs://localhost:9000/hbase-testing</value>
  <description>The directory shared by region servers.
  Should be fully-qualified to include the filesystem to use.
  E.g: hdfs://NAMENODE_SERVER:PORT/HBASE_ROOTDIR
  </description>
</property>
-->

<!-- OPTIONAL: You might want to add these options depending upon your use case


<property>
  <name>dfs.support.append</name>
  <value>true</value>
  <description>Allow append support (if you want to test data durability with HDFS)
  </description>
</property>
-->


</configuration>
